{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6093cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/network/.local/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in /home/network/.local/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /home/network/.local/lib/python3.10/site-packages (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/network/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/network/.local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/network/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/network/.local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/network/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/network/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/network/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/network/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/network/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/network/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/network/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/network/.local/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/network/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/network/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/network/.local/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/network/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn torch pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5cb0de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9b5e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = len(df.columns)\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc96c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "053d3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "class ErrorCorrectionDataset:\n",
    "    def __init__(self, df: pd.DataFrame, ber_pools: List[float], train_size: float = 0.8):\n",
    "        self.df = df\n",
    "        self.ber_pools = ber_pools\n",
    "        self.train_size = train_size\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.original_cols = [c for c in df.columns if c.startswith(\"Original_\")]\n",
    "        self.corrupted_cols = [c for c in df.columns if c.startswith(\"Corrupted_\")]\n",
    "\n",
    "    def _split_tensor(self, sub_df: pd.DataFrame) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Helper to split a dataframe into train/test torch tensors.\"\"\"\n",
    "        n_train = int(self.train_size * len(sub_df))\n",
    "        sub_df = sub_df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "\n",
    "        X = sub_df[self.corrupted_cols].values.astype(\"float32\") / 255.0\n",
    "        y = sub_df[self.original_cols].values.astype(\"float32\") / 255.0\n",
    "\n",
    "        X_train, X_test = X[:n_train], X[n_train:]\n",
    "        y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X_train, dtype=torch.float32).to(self.device),\n",
    "            torch.tensor(y_train, dtype=torch.float32).to(self.device),\n",
    "            torch.tensor(X_test, dtype=torch.float32).to(self.device),\n",
    "            torch.tensor(y_test, dtype=torch.float32).to(self.device),\n",
    "        )\n",
    "\n",
    "    def prepare_datasets(self) -> List[Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Returns a list of datasets (X_train, y_train, X_test, y_test) for each BER pool.\n",
    "        \"\"\"\n",
    "        datasets = []\n",
    "        for ber in self.ber_pools:\n",
    "            sub_df = self.df[self.df[\"BER\"] == ber]\n",
    "            datasets.append(self._split_tensor(sub_df))\n",
    "        return datasets\n",
    "\n",
    "    def generalized_dataset(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns a single dataset (X_train, y_train, X_test, y_test) combining all BER pools.\n",
    "        \"\"\"\n",
    "        return self._split_tensor(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f17fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ber_pools = [0.0, 0.2, 0.5, 0.8]\n",
    "Dataset = ErrorCorrectionDataset(df, ber_pools, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98d2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_datasets = Dataset.prepare_datasets()\n",
    "generalized_dataset = Dataset.generalized_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e8145eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorCorrector(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2dee6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "n_features = num_columns // 2\n",
    "model = ErrorCorrector(n_features).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebb03111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=0.693780\n",
      "Epoch 2, Loss=0.692336\n",
      "Epoch 3, Loss=0.691544\n",
      "Epoch 4, Loss=0.690953\n",
      "Epoch 5, Loss=0.690507\n",
      "Epoch 6, Loss=0.690222\n",
      "Epoch 7, Loss=0.689954\n",
      "Epoch 8, Loss=0.689662\n",
      "Epoch 9, Loss=0.689352\n",
      "Epoch 10, Loss=0.689012\n",
      "Epoch 11, Loss=0.688621\n",
      "Epoch 12, Loss=0.688208\n",
      "Epoch 13, Loss=0.687774\n",
      "Epoch 14, Loss=0.687306\n",
      "Epoch 15, Loss=0.686812\n",
      "Epoch 16, Loss=0.686291\n",
      "Epoch 17, Loss=0.685733\n",
      "Epoch 18, Loss=0.685134\n",
      "Epoch 19, Loss=0.684524\n",
      "Epoch 20, Loss=0.683952\n",
      "Epoch 21, Loss=0.683435\n",
      "Epoch 22, Loss=0.682609\n",
      "Epoch 23, Loss=0.681861\n",
      "Epoch 24, Loss=0.681275\n",
      "Epoch 25, Loss=0.680410\n",
      "Epoch 26, Loss=0.679645\n",
      "Epoch 27, Loss=0.678911\n",
      "Epoch 28, Loss=0.678010\n",
      "Epoch 29, Loss=0.677182\n",
      "Epoch 30, Loss=0.676348\n",
      "Epoch 31, Loss=0.675421\n",
      "Epoch 32, Loss=0.674601\n",
      "Epoch 33, Loss=0.674092\n",
      "Epoch 34, Loss=0.673577\n",
      "Epoch 35, Loss=0.672383\n",
      "Epoch 36, Loss=0.671841\n",
      "Epoch 37, Loss=0.671187\n",
      "Epoch 38, Loss=0.670680\n",
      "Epoch 39, Loss=0.669954\n",
      "Epoch 40, Loss=0.669123\n",
      "Epoch 41, Loss=0.668295\n",
      "Epoch 42, Loss=0.668033\n",
      "Epoch 43, Loss=0.667013\n",
      "Epoch 44, Loss=0.666614\n",
      "Epoch 45, Loss=0.665837\n",
      "Epoch 46, Loss=0.665358\n",
      "Epoch 47, Loss=0.664521\n",
      "Epoch 48, Loss=0.664070\n",
      "Epoch 49, Loss=0.663344\n",
      "Epoch 50, Loss=0.662773\n",
      "Epoch 51, Loss=0.662084\n",
      "Epoch 52, Loss=0.661568\n",
      "Epoch 53, Loss=0.660900\n",
      "Epoch 54, Loss=0.660428\n",
      "Epoch 55, Loss=0.659993\n",
      "Epoch 56, Loss=0.659704\n",
      "Epoch 57, Loss=0.658969\n",
      "Epoch 58, Loss=0.658050\n",
      "Epoch 59, Loss=0.657505\n",
      "Epoch 60, Loss=0.657206\n",
      "Epoch 61, Loss=0.656387\n",
      "Epoch 62, Loss=0.655830\n",
      "Epoch 63, Loss=0.655446\n",
      "Epoch 64, Loss=0.654813\n",
      "Epoch 65, Loss=0.654216\n",
      "Epoch 66, Loss=0.653789\n",
      "Epoch 67, Loss=0.653240\n",
      "Epoch 68, Loss=0.652706\n",
      "Epoch 69, Loss=0.652285\n",
      "Epoch 70, Loss=0.651819\n",
      "Epoch 71, Loss=0.651306\n",
      "Epoch 72, Loss=0.650873\n",
      "Epoch 73, Loss=0.650284\n",
      "Epoch 74, Loss=0.649774\n",
      "Epoch 75, Loss=0.649359\n",
      "Epoch 76, Loss=0.648878\n",
      "Epoch 77, Loss=0.648509\n",
      "Epoch 78, Loss=0.648052\n",
      "Epoch 79, Loss=0.647549\n",
      "Epoch 80, Loss=0.647190\n",
      "Epoch 81, Loss=0.646653\n",
      "Epoch 82, Loss=0.646101\n",
      "Epoch 83, Loss=0.645720\n",
      "Epoch 84, Loss=0.645309\n",
      "Epoch 85, Loss=0.644816\n",
      "Epoch 86, Loss=0.644310\n",
      "Epoch 87, Loss=0.643905\n",
      "Epoch 88, Loss=0.643489\n",
      "Epoch 89, Loss=0.643025\n",
      "Epoch 90, Loss=0.642625\n",
      "Epoch 91, Loss=0.642202\n",
      "Epoch 92, Loss=0.641737\n",
      "Epoch 93, Loss=0.641350\n",
      "Epoch 94, Loss=0.640977\n",
      "Epoch 95, Loss=0.640537\n",
      "Epoch 96, Loss=0.640122\n",
      "Epoch 97, Loss=0.639799\n",
      "Epoch 98, Loss=0.639521\n",
      "Epoch 99, Loss=0.639255\n",
      "Epoch 100, Loss=0.639021\n"
     ]
    }
   ],
   "source": [
    "X_train_00 = error_datasets[0][0]\n",
    "y_train_00 = error_datasets[0][1]\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_00)\n",
    "    loss = criterion(outputs, y_train_00)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23818b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=0.659095\n",
      "Epoch 2, Loss=0.659102\n",
      "Epoch 3, Loss=0.658696\n",
      "Epoch 4, Loss=0.658377\n",
      "Epoch 5, Loss=0.658324\n",
      "Epoch 6, Loss=0.657725\n",
      "Epoch 7, Loss=0.657372\n",
      "Epoch 8, Loss=0.657420\n",
      "Epoch 9, Loss=0.656842\n",
      "Epoch 10, Loss=0.656712\n",
      "Epoch 11, Loss=0.656581\n",
      "Epoch 12, Loss=0.656127\n",
      "Epoch 13, Loss=0.656123\n",
      "Epoch 14, Loss=0.655745\n",
      "Epoch 15, Loss=0.655605\n",
      "Epoch 16, Loss=0.655392\n",
      "Epoch 17, Loss=0.655119\n",
      "Epoch 18, Loss=0.655005\n",
      "Epoch 19, Loss=0.654697\n",
      "Epoch 20, Loss=0.654590\n",
      "Epoch 21, Loss=0.654306\n",
      "Epoch 22, Loss=0.654172\n",
      "Epoch 23, Loss=0.653945\n",
      "Epoch 24, Loss=0.653755\n",
      "Epoch 25, Loss=0.653577\n",
      "Epoch 26, Loss=0.653323\n",
      "Epoch 27, Loss=0.653186\n",
      "Epoch 28, Loss=0.652943\n",
      "Epoch 29, Loss=0.652797\n",
      "Epoch 30, Loss=0.652611\n",
      "Epoch 31, Loss=0.652422\n",
      "Epoch 32, Loss=0.652240\n",
      "Epoch 33, Loss=0.652032\n",
      "Epoch 34, Loss=0.651858\n",
      "Epoch 35, Loss=0.651666\n",
      "Epoch 36, Loss=0.651510\n",
      "Epoch 37, Loss=0.651346\n",
      "Epoch 38, Loss=0.651180\n",
      "Epoch 39, Loss=0.651041\n",
      "Epoch 40, Loss=0.650888\n",
      "Epoch 41, Loss=0.650742\n",
      "Epoch 42, Loss=0.650579\n",
      "Epoch 43, Loss=0.650387\n",
      "Epoch 44, Loss=0.650193\n",
      "Epoch 45, Loss=0.649996\n",
      "Epoch 46, Loss=0.649831\n",
      "Epoch 47, Loss=0.649713\n",
      "Epoch 48, Loss=0.649615\n",
      "Epoch 49, Loss=0.649500\n",
      "Epoch 50, Loss=0.649320\n",
      "Epoch 51, Loss=0.649073\n",
      "Epoch 52, Loss=0.648828\n",
      "Epoch 53, Loss=0.648662\n",
      "Epoch 54, Loss=0.648580\n",
      "Epoch 55, Loss=0.648493\n",
      "Epoch 56, Loss=0.648322\n",
      "Epoch 57, Loss=0.648091\n",
      "Epoch 58, Loss=0.647890\n",
      "Epoch 59, Loss=0.647768\n",
      "Epoch 60, Loss=0.647664\n"
     ]
    }
   ],
   "source": [
    "X_train_02 = error_datasets[1][0]\n",
    "y_train_02 = error_datasets[1][1]\n",
    "\n",
    "for epoch in range(60):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_02)\n",
    "    loss = criterion(outputs, y_train_02)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b319fb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=0.677091\n",
      "Epoch 2, Loss=0.677451\n",
      "Epoch 3, Loss=0.677787\n",
      "Epoch 4, Loss=0.677483\n",
      "Epoch 5, Loss=0.676791\n",
      "Epoch 6, Loss=0.676596\n",
      "Epoch 7, Loss=0.676641\n",
      "Epoch 8, Loss=0.676182\n",
      "Epoch 9, Loss=0.675914\n",
      "Epoch 10, Loss=0.675907\n",
      "Epoch 11, Loss=0.675466\n",
      "Epoch 12, Loss=0.675289\n",
      "Epoch 13, Loss=0.675119\n",
      "Epoch 14, Loss=0.674769\n",
      "Epoch 15, Loss=0.674645\n",
      "Epoch 16, Loss=0.674327\n",
      "Epoch 17, Loss=0.674165\n",
      "Epoch 18, Loss=0.673893\n",
      "Epoch 19, Loss=0.673706\n",
      "Epoch 20, Loss=0.673477\n"
     ]
    }
   ],
   "source": [
    "X_train_05 = error_datasets[2][0]\n",
    "y_train_05 = error_datasets[2][1]\n",
    "\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_05)\n",
    "    loss = criterion(outputs, y_train_05)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eef8879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=0.690970\n",
      "Epoch 2, Loss=0.690746\n",
      "Epoch 3, Loss=0.690396\n",
      "Epoch 4, Loss=0.690054\n",
      "Epoch 5, Loss=0.689600\n",
      "Epoch 6, Loss=0.689132\n",
      "Epoch 7, Loss=0.688616\n",
      "Epoch 8, Loss=0.688094\n",
      "Epoch 9, Loss=0.687588\n",
      "Epoch 10, Loss=0.687144\n"
     ]
    }
   ],
   "source": [
    "X_train_08 = error_datasets[3][0]\n",
    "y_train_08 = error_datasets[3][1]\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_08)\n",
    "    loss = criterion(outputs, y_train_08)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1feb4880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss=0.664328\n",
      "Epoch 2, Loss=0.664662\n",
      "Epoch 3, Loss=0.664613\n",
      "Epoch 4, Loss=0.664188\n",
      "Epoch 5, Loss=0.663560\n",
      "Epoch 6, Loss=0.662773\n",
      "Epoch 7, Loss=0.661944\n",
      "Epoch 8, Loss=0.661126\n",
      "Epoch 9, Loss=0.660486\n",
      "Epoch 10, Loss=0.660104\n",
      "Epoch 11, Loss=0.659872\n",
      "Epoch 12, Loss=0.659651\n",
      "Epoch 13, Loss=0.659421\n",
      "Epoch 14, Loss=0.659322\n",
      "Epoch 15, Loss=0.659249\n",
      "Epoch 16, Loss=0.659121\n",
      "Epoch 17, Loss=0.659037\n",
      "Epoch 18, Loss=0.659040\n",
      "Epoch 19, Loss=0.659243\n",
      "Epoch 20, Loss=0.660288\n"
     ]
    }
   ],
   "source": [
    "X_train = generalized_dataset[0]\n",
    "y_train = generalized_dataset[1]\n",
    "\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss={loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74cdbf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss = 0.662494, Test Byte Accuracy = 0.500357%\n"
     ]
    }
   ],
   "source": [
    "X_test = generalized_dataset[2]\n",
    "y_test = generalized_dataset[3]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # ---- Test metrics ----\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test)\n",
    "\n",
    "    test_preds = (test_outputs * 255).round().int().cpu().numpy()\n",
    "    test_targets = (y_test * 255).round().int().cpu().numpy()\n",
    "    test_acc = (test_preds == test_targets).mean()\n",
    "\n",
    "    print(f\"Test  Loss = {test_loss.item():.6f}, Test Byte Accuracy = {test_acc*100:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70b13d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.662961, Train Byte Accuracy = 0.513877%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # ---- Train metrics ----\n",
    "    train_outputs = model(X_train)\n",
    "    train_loss = criterion(train_outputs, y_train)\n",
    "\n",
    "    train_preds = (train_outputs * 255).round().int().cpu().numpy()\n",
    "    train_targets = (y_train * 255).round().int().cpu().numpy()\n",
    "    train_acc = (train_preds == train_targets).mean()\n",
    "\n",
    "    print(f\"Train Loss = {train_loss.item():.6f}, Train Byte Accuracy = {train_acc*100:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f91045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./error_correction/error_corrector_updated_dataset.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_path = \"./error_corrector_updated_dataset.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
